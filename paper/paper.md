---
title: 'Exploring Bioinformatics in the Wild: Insights from Real LLM Conversations'
title_short: 'Wildchat analysis'
tags:
  - Wildchat
  - Large Language Model
  - Comparative analysis
authors:
  - name: David Steinberg
    orcid:
    affiliation: 1
  - name: Hirokazu Chiba
    orcid:
    affiliation: 2
  - name: Wasin Poncheewin
    orcid: 0000-0003-2267-6872
    affiliation: 3
  - name: Susumu Goto
    orcid:
    affiliation: 2
affiliations:
  - name: University of California, Santa Cruz Genomics Institute, 1156 High St Santa Cruz, CA 95064
    index: 1
  - name: Database Center for Life Science (DBCLS), Japan
    index: 2
  - name: National Center for Genetic Engineering and Biotechnology (BIOTEC), National Science and Technology Development Agency (NSTDA), Khlong Luang 10120, Thailand
    index: 3
date: 30 August 2024
cito-bibliography: paper.bib
event: BH24JP
biohackathon_name: "BioHackathon Japan 2024"
biohackathon_url:   "https://2024.biohackathon.org/"
biohackathon_location: "Fukushima, Japan, 2024"
group: R4
# URL to project git repo --- should contain the actual paper.md:
git_url: https://github.com/biohackathon-japan/bh24-characterize-biology-use-of-llms
# This is the short authors description that is used at the
# bottom of the generated paper (typically the first two authors):
authors_short: Steinberg D. \emph{et al.}
---

# Abstract

# Introduction

The intersection of artificial intelligence and conversational data presents a compelling frontier for research, particularly when exploring specialized fields such as biology and health sciences. The WildChat dataset, with its vast collection of over one million user-chatbot interactions, provides an unparalleled resource for examining how advanced language models engage with a diverse array of topics. Capturing dialogues generated by models like GPT-3.5 and GPT-4, WildChat not only offers a glimpse into everyday conversational dynamics but also holds potential for specialized inquiries.

Understanding how AI handles bioinformatics and health-related conversations is crucial for advancing both AI technology and domain-specific applications. The ability of conversational models to process and respond to complex biological queries can significantly impact research, education, and practical applications in health sciences. By delving into WildChat's dataset, we aim to uncover how these models interpret and manage discussions centered around biology and health, highlighting their effectiveness and areas for improvement.

Our study is driven by the objective to identify and analyze bioinformatics-related interactions within the dataset. Through a focused filtering process and subsequent evaluation using advanced tools, we explore how well these conversations are represented and how different models perform in handling them. This investigation not only sheds light on the capabilities of current conversational AI systems but also provides insights into their potential role in supporting and advancing biological and health science research.

# Related Work

The integration of conversational datasets into bioinformatics research is a burgeoning field with notable advancements and applications. One significant example is the SciQ dataset, a specialized resource that pairs scientific questions with answers, intended to enhance machine comprehension of scientific texts. SciQ exemplifies how conversational and question-answering datasets can be leveraged to improve the interpretability and utility of bioinformatics tools. By focusing on domain-specific queries, SciQ aids in training models to handle complex scientific language and context, which is crucial for bioinformatics applications.

In addition to SciQ, other research has explored the use of conversational datasets for improving scientific literature search and information retrieval. For instance, models trained on general conversational data have been adapted to support scientific inquiry by fine-tuning them on domain-specific corpora. This approach has shown promise in creating more effective tools for extracting and synthesizing information from large volumes of scientific texts.

However, these approaches face several limitations. Many models, while adept at general language understanding, struggle with the specialized vocabulary and context inherent in bioinformatics. Additionally, the existing datasets often lack the depth required for handling nuanced biological queries, which can limit the effectiveness of the models in real-world applications.

By addressing these limitations and expanding the scope of conversational datasets, researchers can develop more robust and context-aware bioinformatics tools. Exploring how conversational data can enhance model performance in handling biological questions offers a promising direction for future research and development in this field.

# Dataset and Filtering

![This figure outlines the analysis and software used. The WildChat dataset was filtered using hand-selected keywords. These prompts were then used to generate responses from a variety of other models. The prompts and responses were vectorized using a sentence embedding model, which were used in performing the analysis of the original and newly generated data. \label{Fig1}](./fig1.pdf)

The WildChat dataset, with its extensive collection of user-chatbot interactions, provides a rich resource for analyzing conversational patterns and exploring specialized domains such as bioinformatics. This dataset includes over a million conversations, capturing a diverse range of topics and user queries, making it a valuable tool for filtering and examining conversations relevant to biological and health sciences.

To identify conversations pertinent to bioinformatics, we employed a keyword-based filtering process. The initial phase involved selecting keywords believed to be relevant to biological research. These initial keywords included terms commonly associated with bioinformatics, such as "genome," "virus," and "bioinformatics." The intent was to capture a broad spectrum of conversations related to these topics.

However, as the filtering process progressed, we encountered challenges with certain broad keywords. For instance, terms like "family" and "kingdom," while relevant in a biological context, also have broader meanings that led to a significant amount of irrelevant data. This issue necessitated a refinement of our keyword list to enhance the specificity and relevance of the filtered conversations.

The refinement process involved iteratively adjusting our keyword selection based on the relevance of the filtered conversations. We employed additional techniques, including semantic analysis using sentence-transformers, to assess the alignment of the conversations with bioinformatics topics. This approach helped in filtering out noise and ensuring that the resulting dataset was more focused on the biological and health science domains.

Through these efforts, we aimed to create a curated subset of the WildChat dataset that better aligns with the objectives of our study, providing a more targeted foundation for subsequent analysis and model evaluation.

# Methods

## Language-Space Analysis

To gain insights into the conversational similarities within the filtered subset of the WildChat dataset, we utilized sentence-transformers. This technique involves embedding prompts and responses into a high-dimensional language space, allowing us to measure semantic similarities between them. By mapping the user prompts onto this space, we could analyze their relative positions and identify clusters of related topics within the bioinformatics domain. This analysis provided valuable information on how closely related different conversations are in terms of their content and language use, and helped us assess whether the prompts fell within the expected thematic areas of bioinformatics. It also revealed patterns and correlations that informed our understanding of the dataset's focus.

## Querying DBCLS Model API

The next step in our methodology involved leveraging the experimental API developed by DBCLS to query various models with the filtered prompts. The API was developed in Python using Flask and exposed as six endpoints, including gpt, gemini, claude3, commandr, llama, and mistral that accept the POST method with model parameters and interact with specific models. The backend of gpt endpoint interacts with OpenAI services deployed on Microsoft Azure. The backend of gemini endpoint interact with Gemini on Google Cloud. The backend of other endpoints interacts with Amazon Bedrock. For all models, temperature is set to 0 and max_tokens are set to 2048. The server developed using Flask includes an HTML and JavaScript code which provide an overview of the results.

In this phase, we designed our queries to explore the capability of different models to handle bioinformatics-related conversations. The queries were crafted based on the refined set of keywords and prompts identified during the filtering process, aiming to cover a range of bioinformatics topics and evaluate how effectively different models could address these queries.

We selected several models for comparison, including both established and experimental ones. By analyzing the responses generated by these models, we assessed their performance in handling bioinformatics-related content and compared their effectiveness. This comparison provided insights into the strengths and limitations of each model in the context of biological and health science conversations.

# Results

## Filtered Dataset Analysis

![Language embeddings of prompts were used to create a t-SNE. Hand curation of topics showed grouping of languages and topics. We found that our topic of interest was mostly represented between math, physics/chemistry, and health categories. \label{Fig2}](./fig2.pdf)

We begin by summarizing the characteristics of the conversations that remained after applying our filtering criteria. This analysis provides an overview of the types of discussions that were successfully identified as bioinformatics-related, including the frequency and diversity of topics covered. A set of 14 keywords were used to filter the dataset. The keywords are bioinformatics, biology, microbiology, notype, genus, phylum, taxonomy, prokaryote, bacteria, fungi, fungal, virus, eukaryote, and gene. This results in a total of 571 prompts from xxx prompts in the dataset. The prompt length was then calculated with the removal of special characters and “stop_words” (https://rdrr.io/cran/tidytext/man/stop_words.html). The distribution of the length is shown in Fig3. The frequency of the words from the prompt are shown in Fig4.

![Histogram showing the length of the prompts calculated with the removal of special characters and “stop_words”. \label{Fig3}](./fig3.pdf)

![Wordcloud showing the frequency of words within the prompts. \label{Fig4}](./fig4.pdf)

The prompts were categorized into different keywords with the inclusion of a “multi” group where there are multiple matches with the keywords. The embedded prompts were filtered for unique embedding, which resulted in 137 prompts in total. The prompts were projected onto the 2D plane using t-SNE [Fig5]. Distance between the represented points were calculated using Euclidean distances [Fig6]. The dendrogram cut-off was heuristically selected at the height of 67 to subset the prompts into 7 clusters. The language-space analysis revealed insightful patterns in how the prompts are distributed and related within the bioinformatics context. By examining the semantic similarities among the prompts, we identified clusters of related topics and assessed the coherence of the filtered dataset with our bioinformatics objectives. This analysis also highlighted the effectiveness of our filtering approach and revealed any potential gaps in the data.

![t-SNE plot of the projected unique embedded prompts. Different colors represent different keyword groups. \label{Fig5}](./fig5.pdf)

![Distances between different embedded prompts represented with a heatmap (top) and a dendrogram (bottom). Both x and y axes of the heatmap were labeled with the keywords using different colors. The cut-off for the dendrogram was heuristically selected at 67 to subset the prompts into 7 clusters, 1 to 7 from left to right”. \label{Fig6}](./fig6.pdf)(./fig7.pdf)
