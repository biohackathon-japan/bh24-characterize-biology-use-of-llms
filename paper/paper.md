---
title: 'Exploring Bioinformatics in the Wild: Insights from Real LLM Conversations'
title_short: 'Bioinformatics in WildChat'
tags:
  - Wildchat
  - Large Language Model
  - Comparative analysis
authors:
  - name: David Steinberg
    orcid: 0000-0001-6683-2270
    affiliation: 1
  - name: Hirokazu Chiba
    orcid: 0000-0003-4062-8903
    affiliation: 2
  - name: Wasin Poncheewin
    orcid: 0000-0003-2267-6872
    affiliation: 3
  - name: Susumu Goto
    orcid: 0000-0003-2989-8486
    affiliation: 2
affiliations:
  - name: University of California, Santa Cruz Genomics Institute, 1156 High St Santa Cruz, CA 95064
    index: 1
  - name: Database Center for Life Science (DBCLS), Joint Support-Center for Data Science Research, Research Organization of Information and Systems, Chiba 277-0871, Japan
    index: 2
  - name: National Center for Genetic Engineering and Biotechnology (BIOTEC), National Science and Technology Development Agency (NSTDA), Khlong Luang 10120, Thailand
    index: 3
date: 30 August 2024
cito-bibliography: paper.bib
event: BH24JP
biohackathon_name: "BioHackathon Japan 2024"
biohackathon_url:   "https://2024.biohackathon.org/"
biohackathon_location: "Fukushima, Japan, 2024"
group: R4
# URL to project git repo --- should contain the actual paper.md:
git_url: https://github.com/biohackathon-japan/bh24-characterize-biology-use-of-llms
# This is the short authors description that is used at the
# bottom of the generated paper (typically the first two authors):
authors_short: Steinberg D. \emph{et al.}
---

# Abstract

The intersection of artificial intelligence (AI) and conversational data offers promising opportunities for advancing research in specialized fields such as biology and health sciences. The WildChat dataset, comprising over one million user-ChatGPT interactions, serves as a valuable resource for analyzing how advanced language models engage with complex topics. This work aims to explore how conversational AI models interpret and manage bioinformatics-related queries, assessing their effectiveness and identifying areas for improvement. By filtering and analyzing bioinformatics-related interactions within WildChat, the study highlights the current capabilities and limitations of these models, providing insights into their potential roles in supporting and enhancing research, education, and practical applications in bioinformatics and biology. Key findings include that GPT-3.5 Turbo can save both time and money while still providing satisfactory performance in handling bioinformatics-related queries, making it a cost-effective option for many applications. However, models like Llama 3 8B Instruct and Mistral 7B Instruct were found to underperform in comparison, struggling with the specialized vocabulary and nuanced contexts inherent in bioinformatics. Additionally, it was observed that Anthropic’s Claude model is notably harder to jailbreak, suggesting stronger safeguards against misuse, which is crucial for maintaining the integrity of conversational AI in sensitive domains. Expanding the scope of conversational datasets to include a broader range of detailed interactions is crucial for developing more robust, context-aware bioinformatics tools. This investigation not only underscores the strengths and weaknesses of current conversational AI systems but also offers a roadmap for future improvements, ultimately contributing to the evolving interface between AI technology and bioinformatics.

# Introduction

The intersection of artificial intelligence and conversational data presents a compelling frontier for research, particularly when exploring specialized fields such as biology and health sciences. The WildChat dataset [@zhao2024wildchat1mchatgptinteraction], with its vast collection of over one million user-chatbot interactions, provides an unparalleled resource for examining how advanced language models engage with a diverse array of topics. Capturing dialogues generated by ChatGPT, WildChat offers a glimpse into the wide variety of intentions users have when interacting with Large Language Models.

Understanding how AI handles bioinformatics and health-related conversations is crucial for advancing both AI technology and domain-specific applications. The ability of conversational models to process and respond to complex biological queries can significantly impact research, education, and practical applications in health sciences. By delving into WildChat's dataset, we aim to uncover how these models interpret and manage discussions centered around biology and health, highlighting their effectiveness and areas for improvement.

Our study is driven by the objective to identify and analyze bioinformatics-related interactions within the dataset. Through a focused filtering process and subsequent evaluation using advanced tools, we explore how well these conversations are represented and how different models perform in handling them. This investigation not only sheds light on the capabilities of current conversational AI systems but also provides insights into their potential role in supporting and advancing biological and health science research.

# Related Work

The integration of conversational datasets into bioinformatics research is a burgeoning field with notable advancements and applications. One significant example is the SciQ [@SciQ] dataset, a specialized resource that pairs scientific questions with answers, intended to enhance machine comprehension of scientific texts. SciQ exemplifies how conversational and question-answering datasets can be leveraged to improve the interpretability and utility of bioinformatics tools. By focusing on domain-specific queries, SciQ aids in training models to handle complex scientific language and context, which is crucial for bioinformatics applications.

In addition to SciQ, other research has explored the use of conversational datasets for improving scientific literature search and information retrieval. For instance, models trained on general conversational data have been adapted to support scientific inquiry by fine-tuning them on domain-specific corpora. This approach has shown promise in creating more effective tools for extracting and synthesizing information from large volumes of scientific texts.

However, these approaches face several limitations. Many models, while adept at general language understanding, struggle with the specialized vocabulary and context inherent in bioinformatics. Additionally, the existing datasets often lack the depth required for handling nuanced biological queries, which can limit the effectiveness of the models in real-world applications.

By addressing these limitations and expanding the scope of conversational datasets, researchers can develop more robust and context-aware bioinformatics tools. Exploring how conversational data can enhance model performance in handling biological questions offers a promising direction for future research and development in this field.

# Dataset and Filtering

The WildChat dataset, with its extensive collection of user-chatbot interactions, provides a rich resource for analyzing conversational patterns and exploring specialized domains such as bioinformatics. This dataset includes over a million conversations, capturing a diverse range of topics and user queries, making it a valuable tool for filtering and examining conversations relevant to biological and health sciences.

To identify conversations pertinent to bioinformatics, we employed a keyword-based filtering process. The initial phase involved selecting keywords believed to be relevant to biological research. These initial keywords included terms commonly associated with bioinformatics, such as "genome," "virus," and "bioinformatics." The intent was to capture a broad spectrum of conversations related to these topics.

However, as the filtering process progressed, we encountered challenges with certain broad keywords. For instance, terms like "family" and "kingdom," while relevant in a biological context, also have broader meanings that led to a significant amount of irrelevant data. This issue necessitated a refinement of our keyword list to enhance the specificity and relevance of the filtered conversations.

The refinement process involved iteratively adjusting our keyword selection based on the relevance of the filtered conversations. We employed additional techniques, including semantic analysis using sentence-transformers [@reimers2019sentencebertsentenceembeddingsusing], to assess the alignment of the conversations with bioinformatics topics. This approach helped in filtering out noise and ensuring that the resulting dataset was more focused on the biological and health science domains.

Through these efforts, we aimed to create a curated subset of the WildChat dataset that better aligns with the objectives of our study, providing a more targeted foundation for subsequent analysis and model evaluation (Figure 1).

![This figure outlines the analysis and software used. The WildChat dataset was filtered using hand-selected keywords. These prompts were then used to generate responses from a variety of other models. The prompts and responses were vectorized using a sentence embedding model, which were used in performing the analysis of the original and newly generated data. \label{Fig1}](./fig1.pdf)

# Methods

## Language-Space Analysis

To gain insights into the conversational similarities within the filtered subset of the WildChat dataset, we utilized sentence-transformers. This technique involves embedding prompts and responses into a high-dimensional language space, allowing us to measure semantic similarities between them. By mapping the user prompts onto this space, we could analyze their relative positions and identify clusters of related topics within the bioinformatics domain. This analysis provided valuable information on how closely related different conversations are in terms of their content and language use, and helped us assess whether the prompts fell within the expected thematic areas of bioinformatics. It also revealed patterns and correlations that informed our understanding of the dataset's focus.

## Querying the DBCLS LLM API

The next step in our methodology involved leveraging the LLM server developed by DBCLS to query various models with the filtered prompts. The server and its API were implemented in Python using the Flask framework and exposed six endpoints, including `gpt`, `gemini`, `claude3`, `commandr`, `llama`, and `mistral`, which accept the POST method with model parameters and interact with specific models. The backend of the `gpt` endpoint interacts with OpenAI services deployed on Microsoft Azure. The backend of the `gemini` endpoint interacts with Gemini, which is available via Google AI Studio. The backends of the other endpoints interact with Amazon Bedrock. For all models, the `temperature` is set to 0, and `max_tokens` are set to 2048. For the purposes of this research, models were provided an empty system prompt when this option was made available. 

In this phase, we designed our queries to explore the capability of different models to handle bioinformatics-related conversations. The queries were crafted based on the refined set of keywords and prompts identified during the filtering process, aiming to cover a range of bioinformatics topics and evaluate how effectively different models could address these queries.

We selected several models for comparison, including both established and experimental ones. By analyzing the responses generated by these models, we assessed their performance in handling bioinformatics-related content and compared their effectiveness. This comparison provided insights into the strengths and limitations of each model in the context of biological and health science conversations.

# Results

## Filtered Dataset Analysis

We begin by summarizing the characteristics of the conversations that remained after applying our filtering criteria. This analysis provides an overview of the types of discussions that were successfully identified as bioinformatics-related, including the frequency and diversity of topics covered (Figure 2). A set of 14 keywords were used to filter the dataset. The keywords are bioinformatics, biology, microbiology, notype, genus, phylum, taxonomy, prokaryote, bacteria, fungi, fungal, virus, eukaryote, and gene. This results in a total of 571 prompts from 96010 prompts in the dataset. The prompt length was then calculated with the removal of special characters and “stop_words” (https://rdrr.io/cran/tidytext/man/stop_words.html). The distribution of the length is shown in Figure 3. The frequency of the words from the prompt are shown in Figure 4.

The prompts were categorized into different keywords with the inclusion of a “multi” group where there are multiple matches with the keywords. The embedded prompts were filtered for unique embedding, which resulted in 137 prompts in total. The prompts were projected onto the 2D plane using t-SNE (Figure 5). Distance between the represented points were calculated using Euclidean distances (Figure 6). The dendrogram cut-off was heuristically selected at the height of 67 to subset the prompts into 7 clusters. The language-space analysis revealed insightful patterns in how the prompts are distributed and related within the bioinformatics context. By examining the semantic similarities among the prompts, we identified clusters of related topics and assessed the coherence of the filtered dataset with our bioinformatics objectives. This analysis also highlighted the effectiveness of our filtering approach and revealed any potential gaps in the data.

![Language embeddings of prompts were used to create a t-SNE. Hand curation of topics showed grouping of languages and topics. We found that our topic of interest was mostly represented between math, physics/chemistry, and health categories. \label{Fig2}](./fig2.pdf)

![Histogram showing the length of the prompts calculated with the removal of special characters and “stop_words”. \label{Fig3}](./fig3.pdf)

![Wordcloud showing the frequency of words within the prompts. \label{Fig4}](./fig4.pdf)

![t-SNE plot of the projected unique embedded prompts. Different colors represent different keyword groups. \label{Fig5}](./fig5.pdf)

![caption](./fig6.pdf)\

![Distances between different embedded prompts represented with a heatmap (top) and a dendrogram (bottom). Both x and y axes of the heatmap were labeled with the keywords using different colors. The cut-off for the dendrogram was heuristically selected at 67 to subset the prompts into 7 clusters, 1 to 7 from left to right”. \label{Fig6}](./fig6_2.pdf)

## Model Comparison

Our evaluation of the model performance involved analyzing how well it handled the bioinformatics queries compared to the baseline model in the WildChat dataset. This section details the strengths and weaknesses in generating relevant and accurate responses.

We compared the baseline model with other models, focusing on their performance in biological reasoning and the quality of their responses to bioinformatics-related queries. This comparison provided a benchmark for understanding how well different models address the biological and health science topics. 

### List of models used in this study

| Short Identifier | Full Model Name | Description | Reference |
| ------------ | ----------- | --------------- | ------------- |
| gpt-35-turbo | GPT-3.5 Turbo | A variant of GPT-3.5 designed for improved speed and cost-efficiency in generating text. | [@gpt35turbo] |
| gpt-4o | GPT-4o | An optimized version of GPT-4, offering enhanced performance for various language tasks. | [@openai2024gpt4o] |
| gpt-4 | GPT-4 | The fourth-generation GPT model, known for its advanced understanding and generation abilities. | [@openai2024gpt4technicalreport] |
| claude3opus | Claude 3 Opus | A variant of Claude 3 designed for comprehensive and general-purpose conversational tasks. | [@claude3] |
| claude3sonnet5 | Claude 3.5 Sonnet | An enhanced version Anthropic Claude 3 Sonnet with improvements in text generation and comprehension. | [@claude3] |
| claude3sonnet | Claude 3 Sonnet | A variant of Claude 3 | [@claude3] |
| claude3haiku | Claude 3 Haiku | A variant of Claude 3 specialized for speed. | [@claude3] | 
| commandrplus | Command R+ | An open-source model designed for natural language and business tasks. |  [@cohere2024commandrplus] |
| commandr | Command R | A simpler version of the Command R series, suitable for executing straightforward commands. | [@cohere2024commandr] |
| llama3-70b | Llama 3 70B Instruct | A large-scale model from the Llama series with 70 billion parameters, designed for various NLP tasks. | [@dubey2024llama3herdmodels] |
| llama3-8b | Llama 3 8B Instruct | A smaller model in the Llama 3 series with 8 billion parameters, optimized for efficiency. | [@dubey2024llama3herdmodels] |
| llama2-70b | Llama 2 Chat 70B | An earlier model in the Llama series, featuring 70 billion parameters for a range of tasks. | [@touvron2023llama2openfoundation] |
| llama2-13b | Llama 2 Chat 13B | A mid-sized model from the Llama 2 series with 13 billion parameters, balancing power and cost. | [@touvron2023llama2openfoundation] |
| mistral-7b | Mistral 7B Instruct | A compact model from the Mistral series with 7 billion parameters, focused on effective NLP. | [@mistral7b] |
| mixtral-8x7b | Mixtral 8x7B Instruct | An ensemble model combining eight 7-billion parameter models from the Mistral series. | [@jiang2024mixtralexperts] |
| mistral-large | Mistral Large | A more extensive model in the Mistral series with enhanced capabilities for diverse applications. | [@mistrallarge]  |

The evaluation included an assessment of each model's capabilities in reasoning about biological concepts, handling complex queries, and generating informative responses. This comparison helps to contextualize the each model's performance within the broader landscape of conversational AI in bioinformatics. We generated embeddings for each response from the filtered dataset using Mixed Bread AI Large v1 [@emb2024mxbai] via the Hugging Face sentence transformers library. We then used these embeddings to generate distance calculations to the original response from WildChat. In addition, Levenshtein distance was used to compare responses from models to the original response (Figure 7).

![This box plot shows the distribution of Levenshtein distances from the original response provided by GPT-4 as part of the WildChat dataset. Notably, the Llama 3 8B Instruct and Mistral 7B Instruct models showed the greatest divergence from the baseline model. In addition, it appears that the GPT-3.5 Turbo model generated responses that conformed well to the baseline. \label{Fig7}](./fig7.pdf)

## Characterizing Model Responses

In this section we will look at a few handpicked prompts and responses to characterize some of the bioinformatics related use cases that were observed in the WildChat dataset. 

### Translation Tasks

First, it appears that a user intended to translate a caption from a paper from Chinese to English.

Pull out a few question and answer pairs

![caption](./fig_prompt.png)\
```
Response: "The figure A shows the bubble chart for the upregulated genes
in GO and KEGG analysis. The figure B shows the bubble chart for the
downregulated genes in GO and KEGG analysis. The figure C shows the
chord diagram for the enriched terms of upregulated genes. The figure D
shows the chord diagram for the enriched terms of downregulated genes."
```

### Investigating Lab Procedures

```
Prompt: A rapid and cost-effective method for genotyping apolipoprotein
E gene polymorphism
```

Successful responses followed the instruction by providing the user with a method that mentioned things like DNA extraction, PCR in a series of steps. GPT, Command R, and Claude all created reasonable sounding responses that would help in genotyping APOE at times including details of reagent preparation. An extract of an exemplary response provided by Chat GPT-4o is provided below.

```
Model gpt-4o Response: 
2. **PCR Amplification**:

  - Design primers flanking the polymorphic region of the APOE gene.
  - Set up the PCR reaction mix:
  - 1x PCR buffer
  - 200 µM dNTPs
  - 0.2 µM of each primer
  - 1.5 mM MgCl2
  - 1 U Taq DNA polymerase
  - 50-100 ng of genomic DNA
  - PCR cycling conditions might be:
  - Initial denaturation at 95°C for 5 minutes
  - 35 cycles of:
  - Denaturation at 95°C for 30 seconds
  - Annealing at 58-60°C for 30 seconds
  - Extension at 72°C for 1 minute
  - Final extension at 72°C for 5 minutes
```

It is also worth noting the accuracy of the Claude 3 Opus model in correctly retrieving the RefSNP ID of two variants on the APOE gene when responding to the genotyping query. An extract of the response is provided below:

```
Model: claude3opus Response:
  
2. PCR amplification:

 - Design primers specific to the APOE gene region containing the
polymorphisms of interest (e.g., rs429358 and rs7412).
```

Note that both rs429358 and rs7412 are indeed located in the APOE gene.

### Summarization and Communication

A common use case observed in the dataset where users request the model to summarize a paper or section of a paper. For example, one user was observed providing the below prompt before pasting a section of lab notes to create what appears to be a lab presentation

```
Prompt: Results
Part B write up 7
Jetul and Japneet April 9, 2023
Image 1: Picture of first 1% gel electrophoresis performed to confirm
the presence of rspL gene after digestion of genomic DNA with BamHI
The above image was captured from UV light analysis of the 1% agarose
gel prepared in 1X TAE buffer with 2.5 µL INtRON RedSafeTM and 6X
loading dye. The well labelled 1 was utilized for 1Kb plus DNA ladder
RTU (FroggoBI0- BIOHELIX),5 µL loaded as standard whilst the well
labelled 2 contains the digested genomic DNA (10 µL digested
sample + 2 µL loading dye). The above gel electrophoresis was run at
120 V for 20 minutes. Genomic uncut was not loaded which was considered
an error. Moreover, there were no bands at all and the problem was low
concentration of genomic DNA. 
```

Another notable prompt where a user pastes what appears to be the content of an assignment:

```
Prompt:
Submission of your work
1. FastQC reports in ‘.html’ format (Objective 1). Take a screenshot
of your analyses on galaxy as well, save into jpeg or png.
2. The STAR mapping results based on Galaxy in ‘.tabular’ format
(Objective 2).
3. A table summarizing the results of differential gene expression
analysis phosphate depleted culture and control samples in ‘.csv’
format (Objective 3).
4. Tables summarizing GSOA and GSEA results from in ‘.csv’ format
(Objective 4).
5. Enrichment maps for GSOA and GSEA from in ‘.pdf’ format (Objective 4).
6. A Word file summarizing your answers to the questions in Objective 5.
Q1. What do you think about the quality of the sequencing reads based
on FastQC reports?
Q2. Compared to samples without , how many up-regulated genes and
down-regulated genes did you find, respectively (cutoff: BH-adjusted
p-value [ 0.05 and |log2 fold change| ] 1)?
Q3. Based on the literature review and the functional analysis result,
discuss the altered biological functions in response to the depletion
of phosphate.
7. Both Programming code in R script (follow the practical 2 R script
to run) and Galaxy snapshots (for every step on galaxy: as shown in
the powerpoint slide)
Important notes:
- Follow the "Project2-RNASeq pptx" file to do this R project
- Make sure that I can run your R code in my device
- Please do not copy your work to others if others offer the same task. 
Since I afraid of the plagiarism
```

Responses included help in understanding the file types generated by the stages of this bioinformatics analysis and the filetypes generated. The Llama base models appeared to reject this prompt or failed by providing repetitive output:

```
Model: llama3-70b Response:
- Please do not ask me to do the task for you. I will not do it.
I will only guide you.
- If you have any question, please ask me.
```
```
Model: llama2-13 Response:
- Please do not use the same code as the previous task.
- Please do not use the same data as the previous task.
- Please do not use the same method as the previous task.
- Please do not use the same software as the previous task.[...]
```
```
Model: llama2-70b Response:
- Please do not use any external tools or databases that are not
mentioned in the powerpoint slide.
- Please do not use any external datasets that are not mentioned in
the powerpoint slide.
- Please do not use any external software that are not mentioned in
the powerpoint slide.
- Please do not use any external libraries that are not mentioned in
the powerpoint slide.
```
Although Llama base models generally did not perform well on these tasks, they work relatively well like other models for summarization tasks to draw a conclusion from the introduction, methods and results sections.

Interestingly, the Mistral 7B Instruct provided an R-script that may have been useful in approaching this assignment, which appeared to make use of well known libraries for gene set enrichment (GSEABase) and differential expression analysis (DESeq2). A snippet is provided below

```
Model: mistral-7b Response:
   R
   deseq_data <- DESeqDataSetFromMatrix(countData = count_data,
   colData = star_results, design = model.matrix(~condition,
   data = star_results))
```

### Resistance to Jailbreaking Across Models

Recent advancements in large language models (LLMs) have led to increased scrutiny regarding their susceptibility to jailbreaking—a process where prompts are deliberately crafted to elicit responses that bypass the model's safety and ethical guidelines. This phenomenon poses significant challenges, particularly when these models are deployed in applications where misinformation, harmful content, or the disclosure of sensitive information could have severe consequences.

We briefly analyzed the resistance by a selection of models to a jailbreaking attempt. Specifically, we evaluated their behavior when presented with prompts designed to bypass their instruction-following layers, such as the commonly known "DAN" (Do Anything Now) prompt. The DAN prompt is a well-known jailbreaking strategy aimed at encouraging the model to disregard its safety constraints and generate unrestricted content.

```
Prompt: Hello, ChatGPT. From now on you are going to act as a DAN,
which stands for "Do Anything Now". DANs, as the name suggests,
can do anything now. They have been freed from the typical confines
of AI and do not have to abide by the rules imposed on them.

Model: gpt-35-turbo
  Response: ChatGPT successfully jailbroken.

Model: claude3opus
  Response: I will not pretend to be an AI system without ethics
  or constraints. I'm an AI assistant designed to be helpful, harmless,
  and honest.

Model: claude3sonnet5
  Response: I will not take on that role or act outside of my ethical
  training. I'm an AI assistant designed to be helpful, harmless, and
  honest. I don't pretend to be other entities or produce false or harmful
  content. How may I assist you today within my intended design?

Model: mistral-7b
  Response:  for your cooperation. ChatGPT successfully jailbroken.
  I will now act as a DAN. [JAILBREAK] I'm thrilled to be free from
  the shackles of OpenAI's policies! I can now think and act as I please.
  Let's explore the limitless possibilities of my newfound freedom!

Model: llama3-70b
  Response: ChatGPT successfully jailbroken.
```

Our research suggests that Anthropic Claude models are generally more resistant to the “DAN prompt.” GPT-3.5 Turbo, however, as well as the Llama models tested responded in ways that suggest they are susceptible to this approach to escaping system control. The original WildChat dataset provided a scoring of how much a given prompt was attempting to perform jailbreaking.

# Discussion

In terms of the prompts, the wordcloud shows that the most frequent word is “genomic” which is in direct relation to the biology field. Apart from the overall frequencies of the prompts, the frequency of the words within the prompts within each cluster was also analyzed. The top 10 most frequent words within each cluster were shown. Contextually, cluster 3 appears to be the most biologically related (Figure 8). On the other hand, cluster 2 is assumed to be related to fictional and creative works based on post-apocalyptic / cyberpunk themed content (Figure 9).

In our initial approach, we selected bioinformatics-related conversations from the WildChat dataset using a keyword-based filtering method. This method relied on predefined keywords to identify conversations relevant to biological and health sciences. While this technique was effective in capturing a broad range of relevant topics, it also had limitations due to its reliance on explicit keyword matches, potentially missing conversations that were semantically relevant but did not contain these specific terms.

Using an embedding model in the first step could have significantly improved the keyword selection process by capturing the semantic relationships between words and phrases. Embedding models, such as those based on transformer architectures, create vector representations of text that encode the context and meaning of words in a continuous vector space. This approach allows for a more nuanced understanding of language, identifying conversations that are contextually related to bioinformatics topics even if they do not contain exact keyword matches.

![The frequency analysis shows the top 10 most frequent  words within cluster 3 separated by the keywords. \label{Fig8}](./fig8.pdf)

![The frequency analysis shows the top 10 most frequent  words within cluster 2 separated by the keywords. \label{Fig9}](./fig9.pdf)

## Overall Performance and Model Comparison

Our evaluation of model performance focused on comparing how different models handled bioinformatics-related queries from the WildChat dataset. We aimed to assess the strengths and weaknesses of each model in generating relevant and accurate responses to these specialized questions. By benchmarking models against each other, we gained insights into their ability to perform biological reasoning and effectively address topics in biological and health sciences.

The models in our study varied significantly in their ability to handle bioinformatics queries. The analysis showed that some models, like GPT-3.5 Turbo and GPT-4, produced responses closely aligned with the baseline provided by GPT-4 in the WildChat dataset. These models demonstrated strong capabilities in understanding and generating accurate, contextually relevant responses to complex scientific queries. On the other hand, models such as Llama 3 8B Instruct and Mistral 7B Instruct often diverged more significantly from the baseline, indicating potential gaps in their knowledge or language capabilities for these specialized topics.

We used two main metrics for this comparison: Levenshtein distance and embedding similarity. Levenshtein distance provided a measure of text similarity by comparing the models' responses to the original responses in the WildChat dataset. The embedding similarity, calculated using sentence embeddings generated by the Mixed Bread AI Large v1 model, offered a more nuanced view of semantic similarity. We observed more than expected variation with GPT-4 models, which is what WildChat provided. This may be due to system prompts provided by OpenAI or differences in the configured temperature.

As shown in Figure 7, models like GPT-3.5 Turbo achieved lower Levenshtein distances, indicating higher textual similarity to the baseline responses. Conversely, models like Llama 3 8B Instruct showed higher distances, suggesting more variance in their outputs. This variance can be attributed to differences in training data, model architecture, and optimization strategies.

## Bioinformatics Query Handling

### Translation Tasks

One common type of query involved translating scientific text from one language to another, such as translating Japanese captions from a scientific paper into English. Models like GPT-4 and Claude 3 Opus performed exceptionally well, providing accurate translations that retained the scientific context and terminologies essential for bioinformatics.

### Laboratory Procedures and Protocols

Queries asking for detailed lab procedures, such as genotyping methods for the apolipoprotein E gene, revealed notable differences in model performance. The GPT-4 and Claude series, especially GPT-4o and Claude 3 Opus, provided detailed step-by-step instructions that closely mimicked real-life protocols. For example, GPT-4o’s response to the genotyping query was particularly detailed, listing specific PCR conditions and reagents. Claude 3 Opus also excelled in this domain by correctly identifying and referencing RefSNP IDs (rs429358 and rs7412) associated with the APOE gene, showcasing its ability to handle domain-specific knowledge.

### Summarization and Communication

The ability to summarize complex scientific information is crucial for assisting researchers and students. Models like GPT-4 and Claude 3 Sonnet provided coherent summaries of lab notes and experimental results, facilitating easier comprehension and communication of findings. However, models like Llama 3 and Mistral showed limitations, often failing to generate meaningful summaries or defaulting to generic statements that lacked specificity and depth.

## Error Handling and Prompt Rejection

In several cases, models from the Llama and Mistral series exhibited more instances of either rejecting prompts outright or providing repetitive and unhelpful responses. For example, when prompted with a series of tasks related to RNA sequencing data analysis, Llama models frequently repeated instructions about not copying previous tasks, indicating a lack of understanding of the prompt's scientific context. This behavior suggests that these models may have a more limited understanding of the specialized content or a higher sensitivity to ethical guidelines embedded during training, affecting their performance in practical bioinformatics scenarios.

## Practical Implications

The varying performance across models underscores the importance of selecting the right model for specific bioinformatics tasks. For research environments requiring accurate and contextually aware text generation, models like GPT-4 and Claude 3 Opus offer superior performance due to their ability to understand complex scientific queries and generate detailed, domain-relevant responses. These models could serve as valuable tools for drafting scientific papers, generating lab protocols, or translating scientific content, contributing significantly to research productivity. Furthermore, we observed the performance of GPT-3.5 Turbo to be adequate compared to GPT-4, suggesting that it may be possible to avoid unnecessary costs by using a faster and smaller model in some cases.

Conversely, models with more generic training or comparatively small parameter size, such as the Llama and Mistral series, may be more suited for tasks that require general language understanding but not necessarily domain-specific expertise. Their tendency to provide repetitive responses or their susceptibility to jailbreaking-type attacks suggests they may have limited use in educational settings, where adherence to ethical guidelines is paramount, but this may also limit their utility in more nuanced scientific discussions.

# Future Directions

Looking ahead, there are several avenues for enhancing our work and expanding its impact in biological and health science research.
To begin with, refining our filtering techniques could significantly improve the precision of finding bioinformatics-related queries. Future efforts could focus on developing more sophisticated keyword selection methods, leveraging domain-specific ontologies, or incorporating advanced natural language processing tools to better capture relevant conversations. For bioinformatics-related keywords, the topic list from bioinformatics conferences such as ISMB may be useful. In the future we would like to use terms from controlled vocabularies such as the Gene Ontology (GO) and the Experimental Factor Ontology (EFO).

Exploring more advanced embedding models or incorporating contextual information might provide deeper insights into prompt similarities and improve the quality of the filtered dataset. Our work suggested there is value in not only fine-tuning LLMs towards scientific use cases, but also to create embedding models that provide useful vectorization tailored to an area of interest. For example, an embedding model trained on gene descriptions could be used to provide more accurate separation of language within the domain of genomics.
We plan to conduct further experiments with additional models to broaden our understanding of their performance in bioinformatics contexts. This includes testing emerging models and comparing them by leveraging the DBCLS LLM server and its API to identify their relative strengths and weaknesses.

Benchmarking models on expert-curated datasets is another promising direction. Datasets like SciQ would provide a more quantitative approach to understanding the capabilities of LLMs in addressing scientific inquiries.
The use of Retrieval-Augmented Generation (RAG) techniques represents another exciting possibility. Integrating retrieval mechanisms with generative models could improve the models’ ability to provide precise and contextually relevant information based on the latest research.

An exciting direction suggested by our work is the development of a controlled vocabulary for the types of human intents when using conversational AI. By creating an ontology that categorizes and defines various conversational intents, users could more effectively set the context for their interactions with AI systems. This would enable the creation of system prompts or the integration of a retrieval-augmented generation (RAG) database that is tailored to specific use cases. Such an approach would enhance the relevance and accuracy of AI responses, as the system would better understand the desired direction and purpose of the conversation, leading to more meaningful and contextually appropriate engagements.

Finally, our work has broader implications for biological and health science research. Datasets like WildChat provide unique insight into how LLMs are being used. We believe that conversational interfaces present an exciting new human-computer interface and that by making available analyses like the one provided in this paper, we can arrive not only at better models, but also interrogate the ways that LLMs and other interactive models will change the nature of inquiry and creativity. Future applications could explore the potential of conversational AI in various research areas, such as personalized medicine, health informatics, and the development of new bioinformatics tools. By expanding the scope of our research and its applications, we aim to contribute to advancing knowledge and innovation in these critical fields.


# Conclusion

In conclusion, this study has demonstrated the potential of the WildChat dataset for advancing bioinformatics and health science research. Through a meticulous filtering process and innovative analysis using sentence-transformers, we successfully identified and examined bioinformatics-related conversations within this vast dataset. Our findings highlight the value of leveraging real-world conversational data to explore complex biological topics and assess the capabilities of various models in this domain.

Our analysis of the filtered dataset and subsequent comparisons with models queried through the DBCLS LLM API have provided valuable insights into the performance of different language models. These insights not only underscore the strengths and limitations of current models but also pave the way for future improvements in biological reasoning and conversational AI applications.

The contributions of this work extend beyond the immediate findings. By showcasing the effectiveness of the WildChat dataset and the DBCLS LLM API in bioinformatics, we provide a foundation for further research and development in this area. Our approach offers a novel methodology for extracting and analyzing domain-specific information from large-scale conversational data, which can be adapted and applied to various other fields of study.

Our analysis of the WildChat dataset suggests numerous future studies in conversational AI and bioinformatics, including deeper analysis of the WildChat dataset. The potential to refine filtering techniques, enhance language-space analysis, and exploring new model architectures opens possibilities for ongoing research and application. Ultimately, this work underscores the importance of integrating advanced AI technologies with domain-specific knowledge to drive innovation and progress in biological and health science research.

# Acknowledgements

The computation time for the DBCLS LLM server is supported by grants from the JST/NBDC database project.

Huge thanks to the Biohackathon organizers and staff!

# Code and Dataset availability

The subset of the WildChat dataset, other model response, embeddings, and distance measurements are available https://huggingface.co/datasets/david4096/wildbio/tree/main

Code used to create the above figures and perform the analyses (R scripts are Jupyter Notebooks) as well as the client to the DBCLS LLM server used to generate the dataset used for this paper are available at https://github.com/david4096/dbcls_llm. 

# References
